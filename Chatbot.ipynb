{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chatbot.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPW7o7dxwXYGeqIjlM0uxkF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swatiaggrawal/Chatbot-by-nltk/blob/main/Chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqrIvYG_lgj_",
        "outputId": "f3957dc0-da51-4ae1-9c88-73a42c04818b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "#mounting google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_root='/content/drive/My Drive/Chatbot'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing required libraries\n",
        "import json\n",
        "import string\n",
        "import random\n",
        "import nltk\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcGzzbvKnQ3F",
        "outputId": "ade39733-b365-4be5-a10a-137381ed2b60"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Load dataset(intents.json)\n",
        "data_file= open('/content/drive/MyDrive/ChatBot/intents.json').read()\n",
        "data = json.loads(data_file) \n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oww7CiaXocm6",
        "outputId": "6fad9854-b78b-4317-8485-633d1b62cdda"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intents': [{'context': [''],\n",
              "   'patterns': ['Hi there',\n",
              "    'How are you',\n",
              "    'Is anyone there?',\n",
              "    'Hey',\n",
              "    'Hola',\n",
              "    'Hello',\n",
              "    'Good day'],\n",
              "   'responses': ['Hello, thanks for asking',\n",
              "    'Good to see you again',\n",
              "    'Hi there, how can I help?'],\n",
              "   'tag': 'greeting'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Bye',\n",
              "    'See you later',\n",
              "    'Goodbye',\n",
              "    'Nice chatting to you, bye',\n",
              "    'Till next time'],\n",
              "   'responses': ['See you!', 'Have a nice day', 'Bye! Come back again soon.'],\n",
              "   'tag': 'goodbye'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Thanks',\n",
              "    'Thank you',\n",
              "    \"That's helpful\",\n",
              "    'Awesome, thanks',\n",
              "    'Thanks for helping me'],\n",
              "   'responses': ['Happy to help!', 'Any time!', 'My pleasure'],\n",
              "   'tag': 'thanks'},\n",
              "  {'context': [''],\n",
              "   'patterns': [],\n",
              "   'responses': [\"Sorry, can't understand you\",\n",
              "    'Please give me more info',\n",
              "    'Not sure I understand'],\n",
              "   'tag': 'noanswer'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How you could help me?',\n",
              "    'What help you provide?',\n",
              "    'How you can be helpful?'],\n",
              "   'responses': ['I can guide you through Adverse management problems, order tracking, person to be contacted and Department related queries',\n",
              "    'I can provide support related to following problems technical query,management related query,order related query,tracking related query,procurement query,outsourcing problem,manufacturing delay,'],\n",
              "   'tag': 'options'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['where is order with id 431B67?',\n",
              "    'track order 562B78',\n",
              "    'Where is my order with id 561A24?'],\n",
              "   'responses': ['Delayed', 'Dispatched', 'On the Way!'],\n",
              "   'tag': 'order_tracking'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['order id 345A23 comprises of?', 'List of components'],\n",
              "   'responses': ['order comprises of hardisk and bluetooth'],\n",
              "   'tag': 'order_components'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['where is the order',\n",
              "    'where is my order',\n",
              "    'locate the order',\n",
              "    'Delivery date of order'],\n",
              "   'responses': ['Please enter with order ID'],\n",
              "   'tag': 'missing_id'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['find order location 32712',\n",
              "    'What is the Location of order 23A31?'],\n",
              "   'responses': ['It is in germany',\n",
              "    'It is in Berlin',\n",
              "    'It has reached china',\n",
              "    'It has reached Banglore'],\n",
              "   'tag': 'Location'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['I want an appoitment with Manoj kumar',\n",
              "    'set an appointment with Sujata Nandi'],\n",
              "   'responses': ['Fixing an appointment.'],\n",
              "   'tag': 'search_person_by_id'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Is my appointment fixed?', 'Do I have an appointment today?'],\n",
              "   'responses': ['Yes', 'NO! Not Yet'],\n",
              "   'tag': 'appointment status'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Is Sujata Nandi on leave?', 'Is Manish Kumar on leave?'],\n",
              "   'responses': ['No Not On Leave', 'Yes On Leave'],\n",
              "   'tag': 'check_leave'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Cost Lowering changes to be made?',\n",
              "    'what changes could lower cost?'],\n",
              "   'responses': ['Increase Transportation capacity utilisation,Increase supply chain velocity,Reduce order variability'],\n",
              "   'tag': 'cost_lowering'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['I forgot my Login password?',\n",
              "    'what to do when someone forgets Login password?',\n",
              "    'I forgot my Laptop password',\n",
              "    'Forgot Wifi password'],\n",
              "   'responses': ['Please enter your email id ,we will send a link on your email'],\n",
              "   'tag': 'forgot_password'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['abx@gmail.com', 'abc@kiit.ac.in'],\n",
              "   'responses': ['Link has been shared.Please change your password'],\n",
              "   'tag': 'email_id'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Find me a manufacturer nearby'],\n",
              "   'responses': ['The nearest manufacturer is Vietnam'],\n",
              "   'tag': 'manufacturing_problems'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['I want to know the various departments in this company'],\n",
              "   'responses': ['The department are:Projects,IT,Production,OutSource'],\n",
              "   'tag': 'search_department'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['what are challenging events',\n",
              "    'what are the threats in the market'],\n",
              "   'responses': ['Recent news of Demonetisation & recession'],\n",
              "   'tag': 'competitors_in_market'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Our Target customers', 'who are your key customers'],\n",
              "   'responses': ['Our target customers are in the range of age 20-40'],\n",
              "   'tag': 'key_customers'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['What information is shared with supplier?'],\n",
              "   'responses': ['Production Schedule,Delivery Schedule,Proxy information about cost'],\n",
              "   'tag': 'supplier_info'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['What is the highest grossing product?'],\n",
              "   'responses': ['Laptop with touch sensors and 360 rotation'],\n",
              "   'tag': 'highest_grossing'},\n",
              "  {'context': ['search_attendance_database_name_post'],\n",
              "   'patterns': ['I want to meet the head of HR/IT/Projects department',\n",
              "    'I want to meet head IT Rakesh sharma.'],\n",
              "   'responses': ['I will just check if he is available or on leave.'],\n",
              "   'tag': 'connect_people'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['complaint has been raised for Insufficient Team Skills',\n",
              "    'Miscommunication Conflicts needs to be resolved',\n",
              "    'Risk Management issue has occured',\n",
              "    'skilled employees needed urgently'],\n",
              "   'responses': ['Please contact the project depatment'],\n",
              "   'tag': 'project_handling_queries'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Lack of product clarity',\n",
              "    'the specifications of product is not clear to customer. what should we do'],\n",
              "   'responses': ['Please enter product id and customer id.specifications shall be sent to user'],\n",
              "   'tag': 'solve_problems'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['user needs the updated software version',\n",
              "    'user demands software updation'],\n",
              "   'responses': ['version updation request raised'],\n",
              "   'tag': 'version_update'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['problem related to Job design and analysis',\n",
              "    'query based on Workforce planning',\n",
              "    'Training and development issues are to be handled',\n",
              "    'Compensation and benefits of the working employee',\n",
              "    'Legal issues of department like accidents in the company'],\n",
              "   'responses': ['Please Contact the HR team for this problem.'],\n",
              "   'tag': 'HR_related_problem'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Impact on sale?', 'factors impacting sale this year?'],\n",
              "   'responses': ['elections will impact our sale this year',\n",
              "    'this year our sale might increase during durga puja',\n",
              "    'this year sale might be impacted due to demonitisation'],\n",
              "   'tag': 'factors_impacting_sale'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['how have we improved our sale from last year?',\n",
              "    'what is the profit this year?'],\n",
              "   'responses': ['we have improved our sale by increasing our customers upto 2 lakh',\n",
              "    'profit earned is 15%'],\n",
              "   'tag': 'predict_performance'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['how was the customer response',\n",
              "    'Is the customer happy?',\n",
              "    'what was the customer feedback?'],\n",
              "   'responses': ['Customer was happy and has given good rating'],\n",
              "   'tag': 'customer_satisfaction'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['maintainence related queries recorded'],\n",
              "   'responses': ['lift is not working, projector misfuctioning'],\n",
              "   'tag': 'maintainence'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['what are the gadgets in stock?', 'which products we have?'],\n",
              "   'responses': ['hardisk,pendrives, wireless bluetooth,Laptops,Gaming Accessories'],\n",
              "   'tag': 'gadgets'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['what is the Commission rate?',\n",
              "    'Commission rate on each product?'],\n",
              "   'responses': ['Commission rate is 5% on laptops,25%on bluetooth device,10% on Desktop'],\n",
              "   'tag': 'commission'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Marry me',\n",
              "    'I love You',\n",
              "    'date me',\n",
              "    'chat with me',\n",
              "    'I am bored'],\n",
              "   'responses': ['Please ask organisation related query.'],\n",
              "   'tag': 'invalid'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['why', 'how', 'when', 'I', 'you'],\n",
              "   'responses': [\"Can't Understand Your Question\",\n",
              "    'please elaborate your question'],\n",
              "   'tag': 'noans'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['what is the turnover of the company at present?'],\n",
              "   'responses': ['10 Million Ton'],\n",
              "   'tag': 'turnover'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['why is order 23A12 delayed'],\n",
              "   'responses': ['delay is due to manufacuring',\n",
              "    'Delay is due to inavailable components'],\n",
              "   'tag': 'predict_delay'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['why is order 23A12 delayed'],\n",
              "   'responses': ['delay is due to manufacuring',\n",
              "    'Delay is due to inavailable components'],\n",
              "   'tag': 'predict_delay'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['what is your name?', 'what should I call you?'],\n",
              "   'responses': [\"I'm Bruno\", \"Hey!I'm Bruno\"],\n",
              "   'tag': 'name'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['how you doing?', 'how are you'],\n",
              "   'responses': ['Thanks For Asking!How can I help you?'],\n",
              "   'tag': 'about'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How to configure my laptop',\n",
              "    'software configuration of laptop',\n",
              "    'steps to configure laptop',\n",
              "    'How to configure my computer',\n",
              "    'software configuration of computer',\n",
              "    'steps to configure computer',\n",
              "    'How to configure my desktop',\n",
              "    'software configuration of desktop',\n",
              "    'steps to configure desktop'],\n",
              "   'responses': ['search tab->control panel->select specific application->download update->give permission'],\n",
              "   'tag': 'configuration'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['what is the weather today?'],\n",
              "   'responses': [\"It's 36C according to accuweather\"],\n",
              "   'tag': 'Weather'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Is Michel Sharma on leave?',\n",
              "    'Is Siddhart Roy present today?',\n",
              "    'Is Shantanu Bhatt in office?'],\n",
              "   'responses': [\"Give me a moment!I'll just check\", 'yes', 'no'],\n",
              "   'tag': 'leave'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['Opening hours of the cafeteria?',\n",
              "    'when does the cafeteria open',\n",
              "    'office canteen opening time'],\n",
              "   'responses': ['It is open from Monday-Saturday 9:00am-7:30pm'],\n",
              "   'tag': 'hours'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['where is VP cabin?',\n",
              "    'Where is Head IT cabin?',\n",
              "    'Where is AI department',\n",
              "    'Where is Project head department?',\n",
              "    'where is cafeteria',\n",
              "    'guide me to the canteen'],\n",
              "   'responses': ['Block-A 3rd floor 1st room',\n",
              "    'Block-B 2nd Floor',\n",
              "    'Block-D Ground Floor'],\n",
              "   'tag': 'cabin'},\n",
              "  {'context': [''],\n",
              "   'patterns': ['How to improve team members domain knowledge',\n",
              "    'improving domain knowledge of team members'],\n",
              "   'responses': ['set up key meetings and workshop,create a shared drive for information,Hold informal sharing session'],\n",
              "   'tag': 'domain'}]}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#creating data_X for words\n",
        "#creting data_Y for classes\n",
        "words=[] #for Bag-of-Words(BoW) model containing patterns\n",
        "classes=[] #for BoW model containing tags\n",
        "data_X=[] #for storing each pattern\n",
        "data_Y=[] #for storing each tag\n",
        "\n",
        "#iterating over all intents\n",
        "for intent in data[\"intents\"]:\n",
        "  for pattern in intent[\"patterns\"]:\n",
        "    tokens=nltk.word_tokenize(pattern) #tokenizing each pattern\n",
        "    words.extend(tokens) # append each token to word\n",
        "    data_X.append(pattern) #append pattern to data_X\n",
        "    data_Y.append(intent[\"tag\"]), #append associated tag to each pattern\n",
        "  # add tag to class if not present\n",
        "  if intent[\"tag\"] not in classes:\n",
        "    classes.append(intent[\"tag\"])\n",
        "#initialize lemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "#lemmatize all word and covert to lowercase if not in punctuation\n",
        "words=[lemmatizer.lemmatize(word.lower()) for word in words if word not in string.punctuation]\n",
        "# sort the vocab and classes in alphabetical order and take set to ensure no duplicates\n",
        "words=sorted(set(words))\n",
        "classes=sorted(set(classes))\n"
      ],
      "metadata": {
        "id": "IllW40yarUxI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting text to numbers\n",
        "training =[]\n",
        "out_empty=[0]*len(classes)\n",
        "#creating BoW model\n",
        "for idx,doc in enumerate(data_X):\n",
        "  bow=[]\n",
        "  text=lemmatizer.lemmatize(doc.lower())\n",
        "  for word in words:\n",
        "    bow.append(1) if word in text else bow.append(0)\n",
        "  #mark index of class associated with current pattern\n",
        "  output_row=list(out_empty)\n",
        "  output_row[classes.index(data_Y[idx])]=1\n",
        "  #add 1 encoded bow and associated classes to training \n",
        "  training.append([bow,output_row])\n",
        "#shuffle data and convert to array\n",
        "random.shuffle(training)\n",
        "training=np.array(training,dtype=object)\n",
        "#split features and target labels\n",
        "train_X=np.array(list(training[:,0]))\n",
        "train_Y=np.array(list(training[:,1]))"
      ],
      "metadata": {
        "id": "mtWpKVVsxd0I"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Neural Network Model\n",
        "model=Sequential()\n",
        "model.add(Dense(128,input_shape=(len(train_X[0]),),activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(64,activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(len(train_Y[0]),activation='softmax'))\n",
        "adam=tf.keras.optimizers.Adam(learning_rate=0.01,decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=adam,metrics=[\"accuracy\"])\n",
        "print(model.summary())\n",
        "model.fit(x=train_X,y=train_Y,epochs=150,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HNElZX0305mX",
        "outputId": "7d19f687-9c69-4e70-85c6-73a0cb30f5d5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 128)               30592     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 44)                2860      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 41,708\n",
            "Trainable params: 41,708\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Epoch 1/150\n",
            "4/4 [==============================] - 3s 6ms/step - loss: 3.8238 - accuracy: 0.0496\n",
            "Epoch 2/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.5543 - accuracy: 0.1405\n",
            "Epoch 3/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.3946 - accuracy: 0.1322\n",
            "Epoch 4/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 3.1073 - accuracy: 0.2149\n",
            "Epoch 5/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.8665 - accuracy: 0.2479\n",
            "Epoch 6/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.6458 - accuracy: 0.3140\n",
            "Epoch 7/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.3334 - accuracy: 0.3967\n",
            "Epoch 8/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 2.0326 - accuracy: 0.4876\n",
            "Epoch 9/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.8691 - accuracy: 0.5124\n",
            "Epoch 10/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.6632 - accuracy: 0.5372\n",
            "Epoch 11/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.5725 - accuracy: 0.5868\n",
            "Epoch 12/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 1.3359 - accuracy: 0.6281\n",
            "Epoch 13/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.1233 - accuracy: 0.6612\n",
            "Epoch 14/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 1.0018 - accuracy: 0.7107\n",
            "Epoch 15/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.8865 - accuracy: 0.7603\n",
            "Epoch 16/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6903 - accuracy: 0.8264\n",
            "Epoch 17/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8984 - accuracy: 0.7438\n",
            "Epoch 18/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.8180 - accuracy: 0.7521\n",
            "Epoch 19/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.7107 - accuracy: 0.7769\n",
            "Epoch 20/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6338 - accuracy: 0.8017\n",
            "Epoch 21/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6054 - accuracy: 0.8182\n",
            "Epoch 22/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6068 - accuracy: 0.7934\n",
            "Epoch 23/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.7104 - accuracy: 0.7851\n",
            "Epoch 24/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4841 - accuracy: 0.8595\n",
            "Epoch 25/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4667 - accuracy: 0.8760\n",
            "Epoch 26/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4336 - accuracy: 0.8843\n",
            "Epoch 27/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5280 - accuracy: 0.8347\n",
            "Epoch 28/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.5345 - accuracy: 0.8512\n",
            "Epoch 29/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4744 - accuracy: 0.8595\n",
            "Epoch 30/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5145 - accuracy: 0.8595\n",
            "Epoch 31/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.6371 - accuracy: 0.8099\n",
            "Epoch 32/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3958 - accuracy: 0.9008\n",
            "Epoch 33/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.8347\n",
            "Epoch 34/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3270 - accuracy: 0.8926\n",
            "Epoch 35/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3941 - accuracy: 0.8843\n",
            "Epoch 36/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3736 - accuracy: 0.8595\n",
            "Epoch 37/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3329 - accuracy: 0.9008\n",
            "Epoch 38/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.8017\n",
            "Epoch 39/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4347 - accuracy: 0.8595\n",
            "Epoch 40/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2266 - accuracy: 0.9339\n",
            "Epoch 41/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4119 - accuracy: 0.8678\n",
            "Epoch 42/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3798 - accuracy: 0.8678\n",
            "Epoch 43/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8843\n",
            "Epoch 44/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3259 - accuracy: 0.8760\n",
            "Epoch 45/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3398 - accuracy: 0.8843\n",
            "Epoch 46/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3441 - accuracy: 0.9091\n",
            "Epoch 47/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3121 - accuracy: 0.9008\n",
            "Epoch 48/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2190 - accuracy: 0.9339\n",
            "Epoch 49/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3668 - accuracy: 0.8843\n",
            "Epoch 50/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3008 - accuracy: 0.8843\n",
            "Epoch 51/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2366 - accuracy: 0.9421\n",
            "Epoch 52/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3491 - accuracy: 0.8843\n",
            "Epoch 53/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4107 - accuracy: 0.8760\n",
            "Epoch 54/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1677 - accuracy: 0.9421\n",
            "Epoch 55/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3018 - accuracy: 0.9091\n",
            "Epoch 56/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2589 - accuracy: 0.9008\n",
            "Epoch 57/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2029 - accuracy: 0.9339\n",
            "Epoch 58/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3387 - accuracy: 0.8926\n",
            "Epoch 59/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2922 - accuracy: 0.9174\n",
            "Epoch 60/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4088 - accuracy: 0.8678\n",
            "Epoch 61/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2320 - accuracy: 0.9256\n",
            "Epoch 62/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3748 - accuracy: 0.8760\n",
            "Epoch 63/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3175 - accuracy: 0.9008\n",
            "Epoch 64/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2339 - accuracy: 0.9174\n",
            "Epoch 65/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1876 - accuracy: 0.9587\n",
            "Epoch 66/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4199 - accuracy: 0.8678\n",
            "Epoch 67/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2942 - accuracy: 0.8760\n",
            "Epoch 68/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3242 - accuracy: 0.8926\n",
            "Epoch 69/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3163 - accuracy: 0.8678\n",
            "Epoch 70/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2852 - accuracy: 0.9008\n",
            "Epoch 71/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3472 - accuracy: 0.8926\n",
            "Epoch 72/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3197 - accuracy: 0.8678\n",
            "Epoch 73/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3590 - accuracy: 0.9008\n",
            "Epoch 74/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4391 - accuracy: 0.8595\n",
            "Epoch 75/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3097 - accuracy: 0.8926\n",
            "Epoch 76/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3046 - accuracy: 0.8843\n",
            "Epoch 77/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3272 - accuracy: 0.8843\n",
            "Epoch 78/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1849 - accuracy: 0.9421\n",
            "Epoch 79/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.9339\n",
            "Epoch 80/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2867 - accuracy: 0.9174\n",
            "Epoch 81/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2753 - accuracy: 0.8926\n",
            "Epoch 82/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4042 - accuracy: 0.8430\n",
            "Epoch 83/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9256\n",
            "Epoch 84/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3850 - accuracy: 0.8512\n",
            "Epoch 85/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1621 - accuracy: 0.9669\n",
            "Epoch 86/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2698 - accuracy: 0.9256\n",
            "Epoch 87/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2930 - accuracy: 0.8843\n",
            "Epoch 88/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1225 - accuracy: 0.9504\n",
            "Epoch 89/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2122 - accuracy: 0.9091\n",
            "Epoch 90/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1968 - accuracy: 0.9256\n",
            "Epoch 91/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3782 - accuracy: 0.8678\n",
            "Epoch 92/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4051 - accuracy: 0.8760\n",
            "Epoch 93/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2870 - accuracy: 0.9421\n",
            "Epoch 94/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2490 - accuracy: 0.9339\n",
            "Epoch 95/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2291 - accuracy: 0.9339\n",
            "Epoch 96/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2321 - accuracy: 0.9256\n",
            "Epoch 97/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3203 - accuracy: 0.9174\n",
            "Epoch 98/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4028 - accuracy: 0.8678\n",
            "Epoch 99/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2780 - accuracy: 0.9174\n",
            "Epoch 100/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2235 - accuracy: 0.9256\n",
            "Epoch 101/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2597 - accuracy: 0.9091\n",
            "Epoch 102/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1453 - accuracy: 0.9587\n",
            "Epoch 103/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3594 - accuracy: 0.9174\n",
            "Epoch 104/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3841 - accuracy: 0.8843\n",
            "Epoch 105/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3708 - accuracy: 0.8678\n",
            "Epoch 106/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3597 - accuracy: 0.8843\n",
            "Epoch 107/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4997 - accuracy: 0.8595\n",
            "Epoch 108/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1961 - accuracy: 0.9256\n",
            "Epoch 109/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3363 - accuracy: 0.9174\n",
            "Epoch 110/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3080 - accuracy: 0.8843\n",
            "Epoch 111/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2075 - accuracy: 0.9091\n",
            "Epoch 112/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3628 - accuracy: 0.8926\n",
            "Epoch 113/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3019 - accuracy: 0.9174\n",
            "Epoch 114/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2668 - accuracy: 0.9008\n",
            "Epoch 115/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3732 - accuracy: 0.9091\n",
            "Epoch 116/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1613 - accuracy: 0.9587\n",
            "Epoch 117/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.3566 - accuracy: 0.9174\n",
            "Epoch 118/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3284 - accuracy: 0.9174\n",
            "Epoch 119/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1434 - accuracy: 0.9504\n",
            "Epoch 120/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2146 - accuracy: 0.9504\n",
            "Epoch 121/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2457 - accuracy: 0.9091\n",
            "Epoch 122/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2890 - accuracy: 0.8926\n",
            "Epoch 123/150\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2413 - accuracy: 0.9256\n",
            "Epoch 124/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3178 - accuracy: 0.9091\n",
            "Epoch 125/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3476 - accuracy: 0.8843\n",
            "Epoch 126/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1596 - accuracy: 0.9339\n",
            "Epoch 127/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.2126 - accuracy: 0.9504\n",
            "Epoch 128/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3023 - accuracy: 0.9174\n",
            "Epoch 129/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2776 - accuracy: 0.9339\n",
            "Epoch 130/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2646 - accuracy: 0.9339\n",
            "Epoch 131/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4654 - accuracy: 0.8926\n",
            "Epoch 132/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2804 - accuracy: 0.9174\n",
            "Epoch 133/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.4681 - accuracy: 0.8264\n",
            "Epoch 134/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3548 - accuracy: 0.9091\n",
            "Epoch 135/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2179 - accuracy: 0.9421\n",
            "Epoch 136/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3412 - accuracy: 0.9174\n",
            "Epoch 137/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2723 - accuracy: 0.8926\n",
            "Epoch 138/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1687 - accuracy: 0.9421\n",
            "Epoch 139/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2590 - accuracy: 0.9008\n",
            "Epoch 140/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8512\n",
            "Epoch 141/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9504\n",
            "Epoch 142/150\n",
            "4/4 [==============================] - 0s 7ms/step - loss: 0.1539 - accuracy: 0.9339\n",
            "Epoch 143/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.4870 - accuracy: 0.9091\n",
            "Epoch 144/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.2890 - accuracy: 0.8926\n",
            "Epoch 145/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3081 - accuracy: 0.9174\n",
            "Epoch 146/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.1805 - accuracy: 0.9339\n",
            "Epoch 147/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.3018 - accuracy: 0.9008\n",
            "Epoch 148/150\n",
            "4/4 [==============================] - 0s 8ms/step - loss: 0.2248 - accuracy: 0.9504\n",
            "Epoch 149/150\n",
            "4/4 [==============================] - 0s 6ms/step - loss: 0.2192 - accuracy: 0.9256\n",
            "Epoch 150/150\n",
            "4/4 [==============================] - 0s 5ms/step - loss: 0.3285 - accuracy: 0.8926\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdce02d27d0>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocessing the input\n",
        "\n",
        "#recieve text and tokenize it \n",
        "def clean_text(text):\n",
        "  tokens=nltk.word_tokenize(text)\n",
        "  tokens=[lemmatizer.lemmatize(word) for word in tokens]\n",
        "  return tokens\n",
        "\n",
        "#convert text into array using BoW model\n",
        "def bag_of_words(text,vocab):\n",
        "  tokens=clean_text(text)\n",
        "  bow=[0]*len(vocab)\n",
        "  for w in tokens:\n",
        "    for idx,word in enumerate(vocab):\n",
        "      if word==w:\n",
        "        bow[idx]=1\n",
        "  return np.array(bow)\n",
        "\n",
        "#return tag corresponding to the highest probablity\n",
        "def pred_class(text,vocab,labels):\n",
        "  bow=bag_of_words(text,vocab)\n",
        "  result=model.predict(np.array([bow]))[0] #extract probablities\n",
        "  thresh=0.5\n",
        "  y_pred=[[indx,res] for indx,res in enumerate(result) if res>thresh]\n",
        "  y_pred.sort(key=lambda x: x[1],reverse=True) #sort values of probablity in decreasing order\n",
        "  return_list=[]\n",
        "  for r in y_pred:\n",
        "    return_list.append(labels[r[0]]) #containing labels/tags with highest probablity\n",
        "  return return_list\n",
        "\n",
        "#takes tag from pred_class and predcict response\n",
        "def get_response(intents_list,intents_json):\n",
        "  if len(intents_list)==0:\n",
        "    result=\"Sorry!!!I don't get it....\" \n",
        "  else:\n",
        "    tag=intents_list[0]\n",
        "    list_of_intents=intents_json[\"intents\"]\n",
        "    for i in list_of_intents:\n",
        "      if i[\"tag\"] == tag:\n",
        "        result=random.choice(i[\"responses\"])\n",
        "        break\n",
        "  return result\n"
      ],
      "metadata": {
        "id": "E24ltqpY7ISq"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#interacting\n",
        "print(\"enter end if you do not want to chat further.\")\n",
        "while True:\n",
        "  message=input(\"\")\n",
        "  if message==\"end\":\n",
        "    break\n",
        "  intents=pred_class(message,words,classes)\n",
        "  result=get_response(intents,data)\n",
        "  print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93aOOi7sA7rj",
        "outputId": "4737e36b-d278-4806-d3f8-73f4fd0bfe7f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "enter end if you do not want to chat further.\n",
            "hi\n",
            "please elaborate your question\n",
            "how are you?\n",
            "Thanks For Asking!How can I help you?\n",
            "what help you provide?\n",
            "I can provide support related to following problems technical query,management related query,order related query,tracking related query,procurement query,outsourcing problem,manufacturing delay,\n",
            "track order 562B78\n",
            "Delayed\n",
            "track order 56\n",
            "On the Way!\n",
            "track order 34901\n",
            "On the Way!\n",
            "end\n"
          ]
        }
      ]
    }
  ]
}